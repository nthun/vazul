@article{MARP2022discussion,
  title = {A Many-Analysts Approach to the Relation between Religiosity and Well-Being: {{Reflection}} and Conclusion},
  author = {Hoogeveen, Suzanne and Sarafoglou, Alexandra and {van Elk}, Michiel and Wagenmakers, Eric-Jan},
  journal={Religion, Brain \& Behavior},
  volume={13},
  number={3},
  pages={356--363},
  year={2023},
  journal = {Religion, Brain, \& Behaviour},
  doi={10.1080/2153599X.2022.2070263}
}
@article{baker2016scientists,
  title={1,500 scientists lift the lid on reproducibility},
  author={Baker, Monya},
  journal={Nature News},
  volume={533},
  pages={452},
  year={2016},
  doi = {10.1038/533452a},
}
@incollection{gelman2016statistical,
  title={The statistical crisis in science},
  author={Gelman, Andrew and Loken, Eric},
  editor={Pitici, Mircea},
  booktitle={The best writing on mathematics},
  volume={102},
  pages={305--318},
  year={2016},
  publisher={Princeton University Press}
}
@article{ioannidis2005most,
  title={Why most published research findings are false},
  author={Ioannidis, John PA},
  journal={PLoS medicine},
  volume={2},
  number={8},
  pages={e124},
  year={2005},
  doi={10.1371/journal.pmed.1004085},
  publisher={Public Library of Science}
}
@article{mcshane2024statistical,
  title={``Statistical Significance'' and Statistical Reporting: Moving Beyond Binary},
  author={McShane, Blakeley B and Bradlow, Eric T and Lynch Jr, John G and Meyer, Robert J},
  journal={Journal of Marketing},
  pages={00222429231216910},
  year={2024},
  doi={10.1177/00222429231216910},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
@article{savitz2024responding,
  title={Responding to Reviewers and Editors About Statistical Significance Testing},
  author={Savitz, David A and Wise, Lauren A and Bond, Julia C and Hatch, Elizabeth E and Ncube, Collette N and Wesselink, Amelia K and Willis, Mary D and Yland, Jennifer J and Rothman, Kenneth J},
  journal={Annals of Internal Medicine},
  year={2024},
  volume={177},
  doi={10.7326/M23-2430},
  pages={385--386},
  publisher={American College of Physicians}
}
@article{muradchanian2021best,
  title={How best to quantify replication success? {A} simulation study on the comparison of replication success metrics},
  author={Muradchanian, Jasmine and Hoekstra, Rink and Kiers, Henk and van Ravenzwaaij, Don},
  journal={Royal Society Open Science},
  volume={8},
  doi={10.1098/rsos.201697},
  pages={201697},
  year={2021},
  publisher={The Royal Society}
}
@article{gilbert2016,
  author = {Daniel T. Gilbert  and Gary King  and Stephen Pettigrew  and Timothy D. Wilson },
  title = {Comment on ``Estimating the reproducibility of psychological science''},
  journal = {Science},
  volume = {351},
  number = {6277},
  pages = {1037-1037},
  year = {2016},
  doi = {10.1126/science.aad7243}
}
@article{camerer2016evaluating,
  title={Evaluating replicability of laboratory experiments in economics},
  author={Camerer, Colin F and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1433--1436},
  year={2016},
  doi={10.1126/science.aaf0918},
  publisher={American Association for the Advancement of Science}
}
@article{pashler2012editors,
  title={Editors' introduction to the special section on replicability in psychological science: {A} crisis of confidence?},
  author={Pashler, Harold and Wagenmakers, Eric-Jan},
  journal={Perspectives on Psychological Science},
  volume={7},
  pages={528--530},
  year={2012},
  doi = {10.1177/1745691612465253},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{nosek2022replicability,
  title={Replicability, robustness, and reproducibility in psychological science},
  author={Nosek, Brian A and Hardwicke, Tom E and Moshontz, Hannah and Allard, Aur{\'e}lien and Corker, Katherine S and Dreber, Anna and Fidler, Fiona and Hilgard, Joe and Kline Struhl, Melissa and Nuijten, Mich{\`e}le B and others},
  journal={Annual review of psychology},
  volume={73},
  pages={719--748},
  year={2022},
  doi = {10.1146/annurev-psych-020821-114157},
  publisher={Annual Reviews}
}
@article{cockburn2020threats,
  title={Threats of a replication crisis in empirical computer science},
  author={Cockburn, Andy and Dragicevic, Pierre and Besan{\c{c}}on, Lonni and Gutwin, Carl},
  journal={Communications of the ACM},
  volume={63},
  number={8},
  pages={70--79},
  year={2020},
  doi={10.1145/3360311},
  publisher={ACM New York, NY, USA}
}
@article{open2015estimating,
  AUTHOR =       {{Open Science Collaboration}},
  TITLE =        {Estimating the Reproducibility of Psychological Science},
  JOURNAL =      {Science},
  doi = {10.1126/science.aac4716},
  YEAR =         {2015},
  volume =       {349},
  pages =        {{aac4716}},
}
@article{ioannidis2005contradicted,
  title={Contradicted and initially stronger effects in highly cited clinical research},
  author={Ioannidis, John PA},
  journal={JAMA},
  volume={294},
  number={2},
  pages={218--228},
  year={2005},
  doi={10.1001/jama.294.2.218},
  publisher={American Medical Association}
}
@article{pfadt2025practicesPreprint,
  title={Methodological Metamorphosis: {The} Rapid Rise of {Bayesian} Inference and Open Science Practices in Psychology},
    author = {Pfadt, M. Julius. and Barto{\v{s}}, Franti{\v{s}}ek and Godmann, R. Henrik. and Waaijers, Meike and Groot, Laura and Heo, Ihnwhi and Mensink, Lotte and Nak, Jason and de Ruiter, P. Jan. and Sarafoglou, Alexandra and Siepe, Bj{\"o}rn and Arena, Giuseppe and Akrong, Emma and Aust, Frederik and van den Bergh, Don and Brenner, Wilhelmine and Doekemeijer, Roos and Donzallaz, C. Michelle and van Doorn, Johnny and Orme{\~n}o Echevarria, Nicol{\'a}s and Finneman, Adam and Geller, Gali and Hato, Tuba and Koskinen, Emily and Krijgsman, Bruny and Kulbe, Lars and L{\"u}ken, Malte and Marsman, Maarten and Ott, L. Vincent and Pawel, Samuel and Piestrak, Olga and de Ron, Jill and Sekulovski, Nikola and Serry, Marlene and Stefan{\'o}w, Alan and Stevenson, Niek and Sadowski, Bartek and Sopuch, M{\'\i}ra and Vasileiou, Antreas and Visser, Ingmar and V{\"o}ller, Marcell and Wiechert, Sera and de Wit, Kay and Wuth, Julian and Wagenmakers, Eric-Jan},
  year={2025},
  journal = {{PsyArXiv}},
  doi = {10.31234/osf.io/ck3js_v1}
}
@article{wicherts2016degrees,
    AUTHOR={Wicherts, Jelte M. and Veldkamp, Coosje L. S. and Augusteijn, Hilde E. M. and Bakker, Marjan and van Aert, Robbie C. M. and van Assen, Marcel A. L. M.},
    TITLE={Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: {A} Checklist to Avoid p-Hacking},
    JOURNAL={Frontiers in Psychology},
    VOLUME={7},
    PAGES={1832},
    YEAR={2016},
    doi={10.3389/fpsyg.2016.01832}
}
@incollection{maccoun2018psychological,
  AUTHOR =       {MacCoun, R. and Perlmutter, S.},
  editor =       {Lilienfeld, S. O. and Waldman, I.},
  booktitle =    {Psychological Science Under Scrutiny: {R}ecent Challenges and Proposed Solutions},
  title =        {Blind Analysis as a Correction for Confirmatory Bias in Physics and in Psychology},
  pages={297--322},
  PUBLISHER =    {John Wiley and Sons},
  YEAR =         {2018},
  doi={10.1002/9781119095910.ch15},
}

@incollection{maccoun2021removebiases,
  title={Blinding to remove biases in science and society},
  author={MacCoun, Robert},
  editor = {Hertwig, R. and Engel, C.},
  booktitle={Deliberate ignorance: {C}hoosing not to know},
  pages={51--64},
  year={2021},
  publisher={MIT Press},
  address={Cambridge}
}
@article{maccoun2015hide,
  title={Blind analysis: {H}ide results to seek the truth},
  author={{MacCoun}, R. and Perlmutter, S.},
  journal={Nature},
  volume={526},
  doi={10.1038/526187a},
  pages={187--190},
  year={2015}
}
@incollection{burger2022network,
  title={Network estimation from time series and panel data},
  author={Burger, Julian and Hoekstra, Ria H A and Mansueto, Alessandra C and Epskamp, Sacha},
  booktitle={Network psychometrics with {R}},
  pages={169--192},
  year={2022},
  publisher={Routledge}
}
@article{epskamp2018gaussian,
  title={The {Gaussian} graphical model in cross-sectional and time-series data},
  author={Epskamp, Sacha and Waldorp, Lourens J and M{\~o}ttus, Ren{\'e} and Borsboom, Denny},
  journal={Multivariate behavioral research},
  volume={53},
  number={4},
  pages={453--480},
  year={2018},
  doi={10.1080/00273171.2018.1454823},
  publisher={Taylor \& Francis}
}
@article{dutilh2021blinding,
  title={Flexible Yet Fair: {B}linding Analyses in Experimental Psychology},
  author={Dutilh, Gilles and Sarafoglou, A. and Wagenmakers, Eric-Jan},
  year={2019},
  journal = {Synthese},
  volume={198},
  pages={S5745--S5772},
  doi={10.1007/s11229-019-02456-7}
}
@article{sarafoglou2025analysis,
  title={Analysis Blinding as a Potential Means to Foster a Productive Collaboration Between Original Authors and Replicators},
  author={Sarafoglou, Alexandra and Hoogeveen, Suzanne},
  journal={Collabra: Psychology},
  volume={11},
  number={1},
  pages={136869},
  year={2025},
  doi={10.1525/collabra.136869},
  publisher={University of California Press}
}
@article{sarafoglou2023comparing,
  title={Comparing analysis blinding with preregistration in the {Many-Analysts Religion Project}},
  author={Sarafoglou, Alexandra and Hoogeveen, Suzanne and Wagenmakers, Eric-Jan},
  journal={Advances in Methods and Practices in Psychological Science},
  volume={6},
  number={1},
  pages={25152459221128319},
  year={2023},
  doi={10.1177/25152459221128319},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
@article{hardwicke2024prevalence2024,
	title = {Prevalence of {Transparent} {Research} {Practices} in {Psychology}: {A} {Cross}-{Sectional} {Study} of {Empirical} {Articles} {Published} in 2022},
	volume = {7},
	issn = {2515-2459, 2515-2467},
	shorttitle = {Prevalence of {Transparent} {Research} {Practices} in {Psychology}},
	doi = {10.1177/25152459241283477},
	language = {en},
	number = {4},
	urldate = {2025-12-02},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Hardwicke, Tom E. and Thibault, Robert T. and Clarke, Beth and Moodie, Nicholas and Crüwell, Sophia and Schiavone, Sarah R. and Handcock, Sarah A. and Nghiem, Khanh An and Mody, Fallon and Eerola, Tuomas and Vazire, Simine},
	month = oct,
	year = {2024},
	pages = {25152459241283477},
}
@article{nagy2025bestiary,
	title = {Bestiary of {Questionable} {Research} {Practices} in Psychology},
	volume = {8},
	issn = {2515-2459, 2515-2467},
	doi = {10.1177/25152459251348431},
	language = {en},
	number = {3},
	urldate = {2025-12-02},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Nagy, Tamás and Hergert, Jane and Elsherif, Mahmoud M. and Wallrich, Lukas and Schmidt, Kathleen and Waltzer, Tal and Payne, Jason W. and Gjoneska, Biljana and Seetahul, Yashvin and Wang, Y. Andre and Scharfenberg, Daniel and Tyson, Gabriella and Yang, Yu-Fang and Skvortsova, Aleksandrina and Alarie, Samuel and Graves, Katherine and Sotola, Lukas K. and Moreau, David and Rubínová, Eva},
	month = jul,
	year = {2025},
	pages = {25152459251348431},
}
@article{hoekstra2025safeguardingPreprint,
  title={Safeguarding Against Bias Without Preregistration: {A} Tutorial on Analysis Blinding for Network Analysis},
  author = {Hoekstra, Ria H A and Huth, Karoline B S and Sekulovski, Nikola and Delhalle, Mia and Sarafoglou, Alexandra},
  year={2025},
  journal = {{PsyArXiv}},
  doi = {10.31234/osf.io/gruw5_v1}
}
@article{SimonsohnEtAl2020,
  AUTHOR =       {Simonsohn, U. and Nelson, L. D. and Simmons, J. P.},
  TITLE =        {Specification curve analysis},
  JOURNAL =      {Nature Human Behaviour},
  YEAR =         {2020},
  volume =       {4},
  doi = {10.1038/s41562-020-0912-z},
  pages =        {1208--1214}
}

@article{steegen2016increasing,
  title={Increasing transparency through a multiverse analysis},
  author={Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
  journal={Perspectives on Psychological Science},
  volume={11},
  pages={702--712},
  year={2016},
  doi={10.1177/1745691616658637},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{gelman2013garden,
  title={The garden of forking paths: {W}hy multiple comparisons can be a problem, even when there is no "fishing expedition" or "p-hacking" and the research hypothesis was posited ahead of time},
  author={Gelman, Andrew and Loken, Eric},
  journal={Department of Statistics, Columbia University},
  volume={348},
  url={http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf},
  year={2013}
}

@article{kerr1998harking,
  title={{HARK}ing: {H}ypothesizing After the Results are Known},
  author={Kerr, N.L.},
  journal={Personality and Social Psychology Review},
  volume={2},
  pages={196--217},
  year={1998},
  doi={10.1207/s15327957pspr0203_4},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{simmons2011false,
  author = {Simmons, J.P. and Nelson, L.N and Simonsohn, U.},
  title ={False--positive Psychology: {U}ndisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant},
  journal = {Psychological Science},
  volume = {22},
  pages = {1359--1366},
  doi={10.1177/0956797611417632},
  year = {2011}
}

@article{vandenakker2024potential,
	title = {The potential of preregistration in psychology: {Assessing} preregistration producibility and preregistration-study consistency},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {1939-1463, 1082-989X},
	shorttitle = {The potential of preregistration in psychology},
	doi = {10.1037/met0000687},
	language = {en},
	urldate = {2025-05-06},
	journal = {Psychological Methods},
	author = {Van Den Akker, Olmo R. and Bakker, Marjan and Van Assen, Marcel A. L. M. and Pennington, Charlotte R. and Verweij, Leone and Elsherif, Mahmoud M. and Claesen, Aline and Gaillard, Stefan D. M. and Yeung, Siu Kit and Frankenberger, Jan-Luca and Krautter, Kai and Cockcroft, Jamie P. and Kreuer, Katharina S. and Evans, Thomas Rhys and Heppel, Frédérique M. and Schoch, Sarah F. and Korbmacher, Max and Yamada, Yuki and Albayrak-Aydemir, Nihan and Alzahawi, Shilaan and Sarafoglou, Alexandra and Sitnikov, Maksim M. and Děchtěrenko, Filip and Wingen, Sophia and Grinschgl, Sandra and Hartmann, Helena and Stewart, Suzanne L. K. and De Oliveira, Cátia M. F. and Ashcroft-Jones, Sarah and Baker, Bradley J. and Wicherts, Jelte M.},
	month = oct,
	year = {2024},
}
@article{peikert2021reproducible,
  title={Reproducible research in {R}: {A} tutorial on how to do the same thing more than once},
  author={Peikert, Aaron and Van Lissa, Caspar J and Brandmaier, Andreas M},
  journal={Psych},
  volume={3},
  number={4},
  pages={836--867},
  year={2021},
  doi={10.3390/psych3040053},
  publisher={MDPI}
}
@article{vanlissa2021worcs,
  title={{WORCS}: {A} workflow for open reproducible code in science},
  author={Van Lissa, Caspar J and Brandmaier, Andreas M and Brinkman, Loek and Lamprecht, Anna-Lena and Peikert, Aaron and Struiksma, Marijn E and Vreede, Barbara MI},
  journal={Data Science},
  volume={4},
  number={1},
  pages={29--49},
  year={2021},
  doi={10.3233/DS-210031},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{schulz2002blinding,
  title={Blinding in randomised trials: {Hiding} who got what},
  author={Schulz, Kenneth F and Grimes, David A},
  journal={The Lancet},
  volume={359},
  number={9307},
  pages={696--700},
  year={2002},
  publisher={Elsevier}
}
@book{pocock2013clinical,
  title={Clinical trials: {A} practical approach},
  author={Pocock, Stuart J},
  year={2013},
  publisher={John Wiley \& Sons}
}
@article{aczel2020transparency,
  AUTHOR =       {Aczel, B. and Szaszi, B. and Sarafoglou, A. and Kekecs, Z. and Kucharsk\'{y}, \v{S} and Benjamin, D. and Chambers, C. D. and
Fisher, A. and Gelman, A. and Gernsbacher, M. A. and Ioannidis, J. P. and Johnson, E. and Jonas, K. and Kousta, S. and
Lilienfeld, S. O. and Lindsay, D. S. and Morey, C. C. and Munaf\`{o}, M. and Newell, B. R. and Pashler, H. and
Shanks, D. R. and Simons, D. J. and Wicherts, J. M. and Albarracin, D. and Anderson, N. D. and Antonakis, J. and
Arkes, H. and Back, M. D. and Banks, G. C. and Beevers, C. and Bennett, A. A. and Bleidorn, W. and Boyer, T. W. and
Cacciari, C. and Carter, A. S. and Cesario, J. and Clifton, C. and Conroy, R. M. and Cortese, M. and Cosci, F. and
Cowan, N. and Crawford, J. and Crone, E. A. and Curtin, J. and Engle, R. and Farrell, S. and Fearon, P. and
Fichman, M. and Frankenhuis, W. and Freund, A. M. and Gaskell, M. G. and Giner--Sorolla, R. and Green, D. P. and Greene, R.
L. and Harlow, L. L. and Hoces de la Guardia, F. and Isaacowitz, D. and Kolodner, J. and Lieberman, D. and Logan, G. D. and
Mendes, W. B. and Moersdorf, L. and Nyhan, B. and Pollack, J. and Sullivan, C. and Vazire, S. and Wagenmakers, Eric-Jan},
  TITLE =        {A Consensus-Based Transparency Checklist},
  JOURNAL =      {Nature Human Behaviour},
  YEAR =         {2020},
  volume =       {4},
  doi =          {10.1038/s41562-019-0772-6},
  pages =        {4--6},
}
@article{Hoekstra2025-ub,
  title    = "Safeguarding against bias without preregistration: A tutorial on
              analysis blinding for network analysis",
  author   = "Hoekstra, Ria H A and Huth, Karoline and Sekulovski, Nikola and
              Delhalle, Mia and Sarafoglou, Alexandra",
  journal  = "PsyArXiv",
  abstract = "Network analysis has become a popular computational modeling
              approach in psychological research and is now increasingly used to
              address confirmatory research questions. However, preregistration
              of such analyses remains rare and given the complexity of the data
              and methods, is often perceived as limiting or even infeasible. In
              this tutorial, we demonstrate how researchers can safeguard
              against bias without relying on preregistration by using analysis
              blinding. The method involves temporarily altering the data to
              remove the key effect of interest while preserving all other
              aspects. Analysis blinding makes it possible to explore important
              features of the data, for instance, spotting outliers or adjusting
              the computational model, without introducing bias. This tutorial
              presents three common research questions in network analysis and
              shows how they can be addressed using analysis blinding to
              safeguard their confirmatory nature. It uses data from previously
              published studies employing network analysis, and offers a
              practical, step-by-step guide along with R code that researchers
              can adapt to their own data and research questions.",
  month    =  nov,
  year     =  2025,
  url      = "https://osf.io/preprints/psyarxiv/gruw5_v1",
  doi      = "10.31234/osf.io/gruw5\_v1",
  language = "en"
}
@article{Sarafoglou2025-fr,
  title     = "Analysis blinding as a potential means to foster a productive
               collaboration between original authors and replicators",
  author    = "Sarafoglou, Alexandra and Hoogeveen, Suzanne",
  journal   = "Collabra. Psychology",
  publisher = "University of California Press",
  volume    =  11,
  number    =  1,
  pages     =  136869,
  abstract  = "Recent awareness of the importance of rigor and robustness have
               deemed replication efforts vital for scientific advance. Yet the
               value of replication projects may often be undermined by post-hoc
               disputes with the original authors about the replication
               outcomes, for instance, concerning data quality, unanticipated
               deviations from the data collection protocol, or diverging
               implementations of the analysis strategy. In this comment, we
               reflect on the tension between replicators and original authors
               and advocate for analysis blinding as a means to prevent such
               unproductive post-hoc discussions. Analysis blinding involves the
               alteration of data to remove the key effect of interest while
               preserving all other aspects. This methodology allows for an
               assessment of important properties of the data (manipulation
               checks, outliers, data quality) without introducing bias or
               risking the perception of attempting to manipulate the results.
               We discuss three replication studies we were responsible for in
               the Holzmeister et al. (2025) project and demonstrate how to
               effectively blind data for each of them. We argue that analysis
               blinding has the potential to prevent fruitless discussions and
               tension between original authors and replication teams in
               replication projects while preserving a healthy scientific
               debate.",
  month     =  may,
  year      =  2025,
  url       = "https://dx.doi.org/10.1525/collabra.136869",
  doi       = "10.1525/collabra.136869",
  issn      = "2474-7394",
  language  = "en"
}

@article{Sarafoglou2023-rf,
  title     = "Comparing Analysis Blinding With Preregistration in the
               Many-Analysts Religion Project",
  author    = "Sarafoglou, Alexandra and Hoogeveen, Suzanne and Wagenmakers,
               Eric-Jan",
  journal   = "Advances in Methods and Practices in Psychological Science",
  publisher = "SAGE Publications Inc",
  volume    =  6,
  number    =  1,
  pages     =  25152459221128319,
  abstract  = "In psychology, preregistration is the most widely used method to
               ensure the confirmatory status of analyses. However, the method
               has disadvantages: Not only is it perceived as effortful and
               time-consuming, but reasonable deviations from the analysis plan
               demote the status of the study to exploratory. An alternative to
               preregistration is analysis blinding, in which researchers
               develop their analysis on an altered version of the data. In this
               experimental study, we compare the reported efficiency and
               convenience of the two methods in the context of the
               Many-Analysts Religion Project. In this project, 120 teams
               answered the same research questions on the same data set, either
               preregistering their analysis (n = 61) or using analysis blinding
               (n = 59). Our results provide strong evidence (Bayes factor [BF]
               = 71.40) for the hypothesis that analysis blinding leads to fewer
               deviations from the analysis plan, and if teams deviated, they
               did so on fewer aspects. Contrary to our hypothesis, we found
               strong evidence (BF = 13.19) that both methods required
               approximately the same amount of time. Finally, we found no and
               moderate evidence on whether analysis blinding was perceived as
               less effortful and frustrating, respectively. We conclude that
               analysis blinding does not mean less work, but researchers can
               still benefit from the method because they can plan more
               appropriate analyses from which they deviate less frequently.",
  month     =  jan,
  year      =  2023,
  url       = "https://doi.org/10.1177/25152459221128319",
  doi       = "10.1177/25152459221128319",
  issn      = "2515-2459"
}
@MISC{Wickham2025-eh,
  title  = "dplyr: A Grammar of Data Manipulation",
  author = "Wickham, Hadley and Fran\c{c}ois, Romain and Henry, Lionel and
            M{\"{u}}ller, Kirill and Vaughan, Davis",
  year   =  2025,
  url    = "https://dplyr.tidyverse.org"
}

@MISC{JASP2025,
AUTHOR = {{JASP Team}},
TITLE = {{JASP (Version 0.95.4)[Computer software]}},
YEAR = {2025},
URL = {https://jasp-stats.org/}
}

@ARTICLE{Thibault2023-of,
  title     = "Reducing bias in secondary data analysis via an Explore and
               Confirm Analysis Workflow ({ECAW}): a proposal and survey of
               observational researchers",
  author    = "Thibault, Robert T and Kovacs, Marton and Hardwicke, Tom E and
               Sarafoglou, Alexandra and Ioannidis, John P A and Munaf\`{o},
               Marcus R",
  journal   = "Royal Society Open Science",
  publisher = "The Royal Society",
  volume    =  10,
  number    =  10,
  pages     =  230568,
  abstract  = "Background. Although preregistration can reduce researcher bias
               and increase transparency in primary research settings, it is
               less applicable to secondary data analysis. An alternative method
               that affords additional protection from researcher bias, which
               cannot be gained from conventional forms of preregistration
               alone, is an Explore and Confirm Analysis Workflow (ECAW). In
               this workflow, a data management organization initially provides
               access to only a subset of their dataset to researchers who
               request it. The researchers then prepare an analysis script based
               on the subset of data, upload the analysis script to a registry,
               and then receive access to the full dataset. ECAWs aim to achieve
               similar goals to preregistration, but make access to the full
               dataset contingent on compliance. The present survey aimed to
               garner information from the research community where ECAWs could
               be applied-employing the Avon Longitudinal Study of Parents and
               Children (ALSPAC) as a case example. Methods. We emailed a
               Web-based survey to researchers who had previously applied for
               access to ALSPAC's transgenerational observational dataset.
               Results. We received 103 responses, for a 9\% response rate. The
               results suggest that-at least among our sample of
               respondents-ECAWs hold the potential to serve their intended
               purpose and appear relatively acceptable. For example, only 10\%
               of respondents disagreed that ALSPAC should run a study on ECAWs
               (versus 55\% who agreed). However, as many as 26\% of respondents
               agreed that they would be less willing to use ALSPAC data if they
               were required to use an ECAW (versus 45\% who disagreed).
               Conclusion. Our data and findings provide information for
               organizations and individuals interested in implementing ECAWs
               and related interventions. Preregistration. https://osf.io/g2fw5
               Deviations from the preregistration are outlined in electronic
               supplementary material A.",
  month     =  oct,
  year      =  2023,
  url       = "https://dx.doi.org/10.1098/rsos.230568",
  keywords  = "ALSPAC; Explore and Confirm Analysis Workflow (ECAW); blind data
               analysis; meta-research; open science; preregistration",
  doi       = "10.1098/rsos.230568",
  pmc       = "PMC10565389",
  pmid      =  37830032,
  issn      = "2054-5703",
  language  = "en"
}

@ARTICLE{Lakens2024-tj,
  title     = "When and how to deviate from a preregistration",
  author    = "Lakens, Dani{\"{e}}l",
  journal   = "Collabra. Psychology",
  publisher = "University of California Press",
  volume    =  10,
  number    =  1,
  pages     =  117094,
  abstract  = "As the practice of preregistration becomes more common,
               researchers need guidance in how to report deviations from their
               preregistered statistical analysis plan. A principled approach to
               the use of preregistration should not treat all deviations as
               problematic. Deviations from a preregistered analysis plan can
               both reduce and increase the severity of a test, as well as
               increase the validity of inferences. I provide examples of how
               researchers can present deviations from preregistrations and
               evaluate the consequences of the deviation when encountering 1)
               unforeseen events, 2) errors in the preregistration, 3) missing
               information, 4) violations of untested assumptions, and 5)
               falsification of auxiliary hypotheses. The current manuscript
               aims to provide a principled approach to deciding when to deviate
               from a preregistration and how to report deviations from an
               error-statistical philosophy grounded in methodological
               falsificationism. The goal is to help researchers reflect on the
               consequence of deviations from preregistrations by evaluating the
               test's severity and the validity of the inference.",
  month     =  may,
  year      =  2024,
  url       = "https://online.ucpress.edu/collabra/article-pdf/10/1/117094/839302/collabra_2024_10_1_117094.pdf",
  doi       = "10.1525/collabra.117094",
  issn      = "2474-7394",
  language  = "en"
}

@ARTICLE{Schneider2022-oq,
  title     = "Do open-science badges increase trust in scientists among
               undergraduates, scientists, and the public?",
  author    = "Schneider, J{\"{u}}rgen and Rosman, Tom and Kelava, Augustin and
               Merk, Samuel",
  journal   = "Psychological Science",
  publisher = "SAGE Publications",
  volume    =  33,
  number    =  9,
  pages     = "1588--1604",
  abstract  = "In three experimental studies, we investigated whether badges for
               open-science practices have the potential to affect trust in
               scientists and topic-specific epistemic beliefs by student
               teachers (n = 270), social scientists (n = 250), or the public (n
               = 257), all of whom were at least 16 years old. Furthermore, we
               analyzed the moderating role of epistemic beliefs for badges and
               trust. Each participant was randomly assigned to two of three
               conditions: badges awarded, badges not awarded, and no badges
               (control). In all samples, our Bayesian analyses indicated that
               badges influence trust as expected, with one exception in the
               public sample: An additional positive effect of awarded badges
               (compared with no badges) was not supported. For students and
               scientists, we found evidence for the relation of badges and
               epistemic beliefs as well as epistemic beliefs and trust.
               Further, we found evidence for the absence of moderation by
               epistemic beliefs.",
  month     =  sep,
  year      =  2022,
  url       = "http://dx.doi.org/10.1177/09567976221097499",
  keywords  = "badges; epistemic beliefs; open data; open materials; open
               science; preregistered; trust",
  doi       = "10.1177/09567976221097499",
  pmid      =  36001881,
  issn      = "0956-7976,1467-9280",
  language  = "en"
}

@ARTICLE{Song2022-em,
  title     = "Trusting on the shoulders of open giants? Open science increases
               trust in science for the public and academics",
  author    = "Song, Hyunjin and Markowitz, David M and Taylor, Samuel Hardman",
  journal   = "The Journal of Communication",
  publisher = "Oxford University Press (OUP)",
  volume    =  72,
  number    =  4,
  pages     = "497--510",
  abstract  = "Abstract Researchers often focus on the benefits of adopting open
               science, yet questions remain whether the general public, as well
               as academics, value and trust studies consistent with open
               science compared to studies without open science. In three
               preregistered experiments (total N = 2,691), we find that the
               general public perceived open science research and researchers as
               more credible and trustworthy than non-open science counterparts
               (Studies 1 and 2). We also explored if open science practices
               compensated for negative perceptions of privately-funded research
               versus publicly-funded research (Study 2), although the evidence
               did not support this hypothesis. Finally, Study 3 examined how
               communication scholars perceive researchers and their work as a
               function of open science adoption, along with publication outlet
               (e.g., high-prestige vs. low-prestige journals). We observed open
               science research was perceived more favorably than non-open
               science research by academics. We discuss implications for the
               open science movement and public trust in science.",
  month     =  aug,
  year      =  2022,
  url       = "https://dx.doi.org/10.1093/joc/jqac017",
  doi       = "10.1093/joc/jqac017",
  issn      = "0021-9916,1460-2466",
  language  = "en"
}

@Manual{R2025,
title = {R: A Language and Environment for Statistical Computing},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
address = {Vienna, Austria},
year = {2025},
url = {https://www.R-project.org/},
}

@MISC{Nagy2026-gb,
  title     = "vazul: An {R} package for analysis blinding",
  author    = "Nagy, Tam\'{a}s and Kov\'{a}cs, M\'{a}rton and Sarafoglou,
               Alexandra",
  publisher = "Zenodo",
  abstract  = "vazul is an R package for data analysis blinding in research
               contexts. It offers two main approaches to anonymize data while
               preserving analytical validity: masking (replacing values with
               anonymous labels) and scrambling (randomizing the order of
               existing values).",
  year      =  2026,
  url       = "http://dx.doi.org/10.5281/zenodo.18269712",
  doi       = "10.5281/ZENODO.18269712"
}
