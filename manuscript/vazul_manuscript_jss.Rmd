---
documentclass: jss
author:
  - name: Tamás Nagy
    orcid: 00000-0001-5244-0356
    address: |
      | Institute of Psychology,
      | ELTE Eötvös Loránd University,
      | Budapest, Hungary
    affiliation: |
      | ELTE Eötvös Loránd University
    email: \email{nagy.tamas@ppk.elte.hu} \AND
  - name: Márton Kovács
    orcid: 0000-0002-8142-8492
    address: |
      | Budapest, Hungary
    affiliation: |
      | Independent researcher
    email: \email{marton.balazs.kovacs@gmail.com} \AND    
  - name: Alexandra Sarafoglou
    orcid: 0000-0003-0031-685X
    address: |
      | Department of Psychology,
      | University of Amsterdam,
      | Amsterdam, The Netherlands
    affiliation: |
      | University of Amsterdam
    email: \email{a.s.g.sarafoglou@uva.nl} 
title:
  # If you use tex in the formatted title, also supply version without
  # For running headers, if needed
  formatted: "\\pkg{vazul}: An R Package for Analysis Blinding"
  plain:     "An R Package for Analysis Blinding"
  short:     "\\pkg{vazul}: An R Package for Analysis Blinding"
abstract: >
  Analysis blinding is a methodological approach designed to protect the confirmatory status of an analysis by concealing crucial test-relevant aspects of the data from the analysts. This article introduces the vazul package for R, which provides a comprehensive suite of tools for implementing masking and scrambling techniques. We discuss the theoretical foundations of analysis blinding, particularly as a complement or alternative to preregistration. 
  
  The package allows researchers to maintain analytic flexibility while safeguarding against bias. By using vazul, data managers can easily generate blinded datasets that preserve essential distributional properties while obscuring associations or labels that could lead to biased decisions. We provide detailed examples of vector-level, data-frame-level, and row-wise blinding operations, and demonstrate how the package handles complex data structures such as hierarchical or repeated-measures designs.
keywords:
  # at least one keyword must be supplied
  formatted: [analysis blinding, R package, bias control]
  plain:     [analysis blinding, R package, bias control]
preamble: >
  \usepackage{amsmath}
output: rticles::jss_article
bibliography: ../inst/bibliography.bib
csl: jss.csl  
editor_options: 
  chunk_output_type: inline
---

```{r defaults, include=FALSE}
library(knitr)

options(prompt = 'R> ', continue = '+ ')
```

# Introduction

In data analysis, researchers face the challenge of maintaining objectivity and minimizing bias. A central concern is the considerable analytic flexibility present at various stages of the workflow, including data preprocessing, variable selection, model specification, and statistical testing. This flexibility has been described as the "garden of forking paths" [@gelman2013garden], meaning that possibly hundreds or thousands of plausible, non-redundant analytic strategies can be applied to the same dataset [@steegen2016increasing; @SimonsohnEtAl2020]. Crucially, different analytic paths can yield different results, and analysts may, intentionally or not, gravitate toward those that align with their expectations. 

The result can be biased or even spurious findings [@ioannidis2005most; @simmons2011false; @gelman2016statistical], which have eroded trust in science and contributed to replication failures across medical sciences, psychology, economics, and computer science [@ioannidis2005contradicted; @open2015estimating; @baker2016scientists; @nosek2022replicability; @pashler2012editors; @camerer2016evaluating; @cockburn2020threats].^[But see @gilbert2016, @muradchanian2021best, @savitz2024responding, and @mcshane2024statistical for critiques of how replication failure is measured and of the design and validity of some replication attempts.] To ensure the reliability of empirical findings, it is therefore essential to prevent the idiosyncrasies of the data from feeding back into the formulation of the hypotheses being tested [HARKing, @kerr1998harking] or from prompting researchers to exploit their analytic freedom to accentuate desired outcomes [@simmons2011false]. In response, researchers have proposed methodologies to limit the influence of bias in data analysis. One such method is analysis blinding, which supplies analysts with an altered version of the real data that conceals biasing features until the analysis plan is finalized.

Analysis blinding, or blind analysis [@maccoun2015hide; @maccoun2018psychological], is a methodological approach designed to protect the confirmatory status of an analysis by concealing crucial test-relevant aspects of the data from the analysts—for example, by scrambling dependent variables or masking condition labels. The procedure typically involves two independent parties: a data manager, who has full access to the raw data and is responsible for implementing the blinding steps, and an analyst, who is tasked with developing the analysis plan. After the data manager applies the blinding procedure, the analyst receives the resulting modified dataset: the blinded data.

Working with the blinded data, the analyst can explore and preprocess the dataset and develop an analysis plan without being influenced by whether a particular analytic choice produces the desired result, as any patterns in the blinded data are, by design, only a product of chance. Importantly, although the test-relevant elements are concealed, other meaningful characteristics remain intact, including demographic information, secondary variables, and the distributional properties of both dependent and independent variables. As a result, the analyst retains all information necessary to tailor the analytic approach to the specific, and potentially unexpected, features of the data. Once the analysis plan has been finalized using the blinded data, the analyst is granted access to the raw, unblinded dataset, and the confirmatory analysis can then be carried out strictly according to the pre-established plan.

Analysis blinding ties in with other methodologies to minimize bias in the research cycle, such as single-blind or double-blind experimental designs, where participants and/or experimenters are unaware of certain aspects of the study to prevent bias in data collection [@schulz2002blinding]. Here, the analysts are intentionally kept unaware of certain aspects of the data to prevent bias in data analysis, which is why the methodology is also referred to as triple-blind [@schulz2002blinding]. 

Although many blinding techniques are conceptually straightforward, such as scrambling outcome variables or masking variable names and factor labels, their practical implementation can become technically challenging once real research designs and data structures are considered. For instance, in hierarchical models, researchers may need to scramble the outcome variable to destroy the effect of interest while still preserving information within grouping levels, such as country-level means in cross-cultural datasets [e.g., @sarafoglou2023comparing]. Similarly, in repeated-measures designs, condition labels may need to be masked so that each participant’s condition structure is preserved while permuting the mapping of conditions across participants to obscure the true experimental effect. These complexities make manual analysis blinding difficult to carry out consistently and correctly. To lower barriers for data managers and facilitate the broader adoption of analysis blinding in research labs, dedicated software tools, such as \proglang{R} packages, are needed to implement these procedures reliably.

To meet this need, the \pkg{vazul}^[Vazul was an 11th-century Hungarian prince of the Árpád dynasty, a cousin of King Stephen I (c. 975–1038). Around 1031, Vazul was blinded—according to contemporary chronicles-to make him unfit for succession to the throne. In the same spirit, the \pkg{vazul} package helps create blinded data that are unfit for p-hacking.] package  [@Nagy2026-gb] in \proglang{R} [@R2025] offers flexible and reproducible tools for implementing analysis blinding. The \proglang{R} package provides functionality for data scrambling as well as data and variable masking. In the remainder of this article, we introduce the methodology in more detail, describe the functionalities of the \pkg{vazul} package, and illustrate its application through practical examples. We conclude with a brief discussion and outline future directions.

## Analysis Blinding: Safeguarding Against Bias Without Preregistration

Originally, analysis blinding gained traction in astrophysics in the early 2000s [@maccoun2018psychological] as a means of safeguarding analysts against bias. Since then, the methodology has also been advocated in the social and behavioral sciences as an alternative or complement to preregistration [@dutilh2021blinding; @nagy2025bestiary; @maccoun2021removebiases; @maccoun2015hide; @maccoun2018psychological; @aczel2020transparency]. 

This interest partly reflects the fact that analysis blinding addresses practical limitations of preregistration when analytic flexibility is required. While preregistration provides a valuable framework for increasing transparency, analysts may nonetheless encounter unexpected features of the data that necessitate deviations from the preregistered plan. Such deviations are common and often unavoidable, and when transparently reported and justified, they can enhance the credibility and validity of research findings [e.g., @vandenakker2024potential; @Lakens2024-tj; @Schneider2022-oq; @Song2022-em]. 

At the same time, preregistration offers limited guidance on how analytic decisions should be adapted in response to unforeseen data characteristics, and how such deviations should be interpreted with respect to confirmatory status. As a result, researchers may face a tension between adhering strictly to a preregistered plan and making principled, data-informed adjustments. Analysis blinding alleviates this tension by allowing analysts to flexibly develop and refine analysis plans using blinded data, before any test-relevant information is revealed.

In contrast to preregistration, analysis blinding allows researchers to maintain flexibility in their analysis plans, as they can explore the data without being constrained by a rigid preregistered protocol. This flexibility is especially important in analyses involving advanced statistical modeling or preprocessing, where not all decisions can be anticipated in advance and researchers must make data-dependent choices. For instance, many psychological constructs, such as well-being, are measured with multi-item scales whose factor structure must be examined before further analysis; whether the items load onto a single factor or multiple factors determines subsequent analytic steps, including whether composite scores can be computed or whether a more complex measurement model is required [see e.g., @MARP2022discussion]. The flexibility gained by analysis blinding enables researchers to develop analysis strategies that are appropriately tailored to the specific characteristics of the dataset without the need to anticipate and specify all eventualities in advance. Consequently, researchers who analyze their data with analysis blinding are less likely to deviate from their developed analysis plan compared to researchers who preregister their analytic strategy in a text-based format [@sarafoglou2023comparing].

Moreover, similar in spirit to approaches proposed in code-based preregistration [@peikert2021reproducible; @vanlissa2021worcs], analysis blinding naturally produces analysis plans that are specific, precise, and exhaustive, because they are written directly in code rather than described verbally in preregistration templates. As with preregistration, analysis scripts based on the blinded data can be uploaded or attached to preregistration platforms (e.g., the Open Science Framework) to provide a transparent record of the planned analysis before the data are unblinded. In short, analysis blinding can serve as a valuable alternative or additional safeguard to preregistered analysis plans: it effectively protects against bias while providing analysts with the flexibility needed to develop an analysis strategy that is optimally suited to their data. Notably, even when the blinding code itself is shared, the original data cannot be recovered from the blinded dataset without access to the raw data, making analysis blinding compatible with transparent and open workflows.

Analysis blinding can be particularly valuable for secondary data analysis, where the confirmatory power of preregistration is often compromised by prior exposure to the data [@Thibault2023-of]. In archival datasets, large-scale surveys, or shared repositories, researchers may already possess unavoidable knowledge of variable distributions or previously reported associations. By developing and finalizing analysis plans on a blinded version of the existing data, researchers can maintain analytic flexibility while providing a verifiable safeguard against post-hoc bias. This approach effectively protects the confirmatory status of the study in contexts where traditional preregistration might otherwise be perceived as impractical or insufficient.

# Overview of the main functions 

The package provides functions for two main types of analysis blinding:

1. **Masking**: Replaces original values with anonymous labels, completely hiding the original information.
2. **Scrambling**: Randomizes the order of existing values while preserving all original data content.

## Choosing between masking and scrambling

When choosing between masking and scrambling for analysis blinding, the decision usually turns on what information must be concealed and what structure must be preserved to allow for the development of a suitable analysis pipeline. Masking is most appropriate when the risk lies in the labels of categories rather than their relationships. By replacing group names (e.g., 'Treatment' and 'Control') with arbitrary codes (e.g., 'Group A' and 'Group B'), the group allocation is preserved. This allows analysts to perform group-level operations—such as ANOVA or regression—while remaining blinded to the substantive identity of those groups. Note, that since group-level distinctions remain intact, masking is best suited for workflows where knowing the direction of a difference would not inadvertently reveal the underlying category meaning. Masking also accommodates cases where different variables require different relabeling schemes or prefixes, for example when several independent categorical factors need to remain distinguishable but substantively opaque. This approach is common in clinical trials, behavioral experiments, and preregistered confirmatory analyses where preserving the structure of factors is essential but knowledge of factor identity would bias analytic choices. For instance, an analyst can check for data consistency across four masked study sites (e.g., "Site A" through "Site D") to ensure uniform data quality without knowing the specific geographic locations. This preserves the site-level grouping for variance testing while preventing biased assumptions about data from specific regions.

Masking can be indispensable in situations where the variable names themselves carry substantive meaning. This occurs, for example, in network analysis, where variables become nodes with interpretable labels, or in factor-analytic work, where item names often hint at their latent content [@Hoekstra2025-ub]. In such settings, simply scrambling values would not prevent analysts from inferring the underlying constructs, whereas masking removes this semantic cue entirely. The \pkg{vazul} package supports this use case directly by offering functionality for masking variable names alongside their values.

Scrambling becomes the better choice when the goal is to preserve the marginal distributions of numeric variables while severing their hypothesized associations. It is particularly useful in settings where analysts need access to realistic distributions—variance, skew—to make decisions about transformations, model families, or robustness checks, yet must remain blind to the relationship between predictors and outcomes. By permuting values within variables, scrambling prevents recognition of treatment or experimental effects, correlations, or temporal patterns, making it harder to inadvertently tune an analysis toward the desired result. It is often the preferred option in longitudinal studies, high-dimensional observational datasets where categorical relabeling would either destroy important numeric structure or be easy to reverse-engineer (e.g., in case of three experimental conditions, the researcher may guess which one is which based on the means). Scrambling is generally the more versatile option, because it can be applied across variable types and adapts well to a wide range of study designs and analytic workflows. Its ability to break associations while preserving distributions makes it suitable for almost everything from tightly controlled experiments to complex observational datasets, including high-dimensional or mixed-format data [@Sarafoglou2025-fr; @Sarafoglou2023-rf].

| **Aspect**                               | **Masking**                                                                                        | **Scrambling**                                                                       |
| ---------------------------------------- | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ |
| Original values                      | Replaced with arbitrary codes                                                                      | Preserved but permuted                                                               |
| Data distribution                    | Category counts preserved with different labels                             | Marginal distributions fully preserved                                               |
| Associations with blinded variables       | Preserved                                                                                          | Broken (correlations, treatment–outcome links removed)                               |
| Risk addressed                       | Hiding the identity or meaning of categories or variable names                                     | Preventing recognition of true relationships or effects                              |
| Best suited for                      | Categorical variables with many different labels; variables whose names convey substantive meaning                            | Numeric or categorical variables; mixed-type data                        |
| Typical use cases                    | Clinical trials, behavioral experiments, network analysis, factor analysis | Longitudinal data, observational datasets, robustness checks   |
| When essential                       | When variable names or category labels carry substantive information                               | When analysts need realistic numeric structure but must remain blind to associations |
| Flexibility across research settings | Limited by categorical/semantic constraints                                                        | Broadly applicable to most data types and study designs                              |
:Comparison of masking and scrambling approaches for analysis blinding.


In the \pkg{vazul} package, each approach is available at three levels:

- **Vector level**: `mask_labels()` and `scramble_values()` - operate on single vectors
- **Data frame level**: `mask_variables()` and `scramble_variables()` - operate on columns in a data frame
- **Row-wise level**: `mask_variables_rowwise()` and `scramble_variables_rowwise()` - operate within rows across columns

The design of these three levels reflects the common ways researchers interact with data in \proglang{R}. Vector-level functions are the primary building blocks, designed for simple pipelines where a researcher might want to blind a single outcome or a specific grouping factor. These functions are particularly useful when working with \pkg{dplyr}'s `mutate()` or within custom functions where a specific variable needs to be isolated and transformed without affecting the rest of the environment [@Wickham2025-eh]. By providing these atomic operations, \pkg{vazul} ensures that the core blinding logic remains accessible even for non-standard data structures.

Moving to the data frame and row-wise levels, the package addresses more complex research designs. Data frame-level functions allow for bulk operations, which are essential for datasets with dozens of variables requiring consistent masking or independent scrambling. The row-wise operations solve a frequent headache in repeated-measures and longitudinal research. In these designs, the "unit" of analysis is often spread across multiple columns (e.g., independent varibles in factorial designs); the row-wise functions ensure that the relationship within a participant's data is handled correctly—either by scrambling values across those specific time points for each person or by applying a consistent mask that hides the identity of the measurement while preserving the participant-level structure.

All of the functions require a data frame or vector as input and return a modified version with masked or scrambled values. The original data structure, including class attributes and metadata, is carefully preserved to ensure that the blinded data can be passed directly into existing analysis scripts or visualization packages without requiring additional type conversions.


| Function | Level | Purpose |
|----------|-------|---------|
| `mask_labels()` | Vector | Replace categorical values with anonymous labels |
| `mask_variables()` | Data frame | Mask multiple columns |
| `mask_variables_rowwise()` | Row-wise | Masking within rows |
| `mask_names()` | Variable names | Mask column names |
| `scramble_values()` | Vector | Randomize value order |
| `scramble_variables()` | Data frame | Scramble multiple columns |
| `scramble_variables_rowwise()` | Row-wise | Scramble values within rows |
: Overview of vazul functions for masking and scrambling data

The \pkg{vazul} package is open source and distributed via CRAN and GitHub  (\url{https://github.com/nthun/vazul}). All analyses reported here were conducted using version 1.0.0.

In the following sections, we provide detailed descriptions and examples for each of these functions, illustrating their use cases and practical applications in research workflows. We starts with setting up the environment and loading the included datasets.

```{r setup, message=FALSE}
library(vazul)
library(dplyr)

set.seed(1037)

data(marp)
data(williams)
```

## Included datasets

The \pkg{vazul} package includes two research datasets for demonstration and practice. The `marp ` dataset contains cross-national survey data on religiosity [@MARP2022discussion], while the `williams` dataset contains experimental data from a stereotyping study [@Sarafoglou2025-fr].

## Masking functions

Masking functions replace categorical values with anonymous labels. This is useful when you want to hide the original information, such as treatment conditions or group assignments, and there are a limited number of unique values. The `mask_labels()` function takes a character or factor type vector and replaces each unique value with a randomly assigned masked label. The function preserves factor structure when the input is a factor. After masking, each unique value receives a unique masked label, the same original value always maps to the same masked label, and the assignment of masked labels to original values is randomized. Missing values are preserved during masking.

```{r mask_labels_example}
# Create a simple treatment vector
treatment <- c("control", "treatment_1", "treatment_2", "control", "treatment_1", "treatment_2")

# Mask the labels
mask_labels(treatment)

```

It is possible to customize the prefix used for masked labels:

```{r mask_labels_groups}
mask_labels(treatment, prefix = "group_")
```

The `mask_variables()` function extends the masking functionality to multiple columns in a data frame simultaneously. It is possible to use tidyelect helpers to select columns. for instance, in the MARP dataset, we want to simultaneously mask labels within the columns "country" and "denomination". To make the example manageable, we first create a smaller example dataset with 10 random rows. Then we demonstrate how to use `mask_variables()` to mask the selected columns. It is possible to use tidyselect helpers (such as `starts_with()`, `any_of()`, etc.) to select columns. In the next example, we apply masking to all character columns in the example dataset.

```{r}
marp_example <-
    marp |>
    select(subject, country, denomination) |> 
    sample_n(6)

marp_example
    
marp_example |> 
    mask_variables(c("country", "denomination"))

marp_example |> 
    mask_variables(where(is.character))

```

By default, each column gets its own set of masked labels with the column name as prefix. When `across_variables = TRUE`, all selected columns share the same mapping. This can be useful when the same conditions appear in multiple columns.

```{r}
df <- data.frame(pre_condition = c("A", "B", "C", "D"),
                 post_condition = c("B", "D", "D", "C"),
                 id = c(1, 2, 3, 4)
                 )
df

mask_variables(df, 
               c("pre_condition", "post_condition"),
               across_variables = TRUE)
```

The `mask_variables_rowwise()` function applies consistent masking within each row across multiple columns. This is useful for example in factorial designs or repeated measures designs, where multiple independent variables require concealment. Within each row, the original values are consistently mapped to masked labels, but the mapping is independent across rows. The function can use tidyselect helpers. In the next example, we show how to mask treatment conditions across multiple waves of a longitudinal study.

```{r}
df <- data.frame(id = 1:3,
                 wave_1 = c("control", "treatment_1", "treatment_2"),
                 wave_2 = c("treatment_1", "treatment_2", "control"),
                 wave_3 = c("treatment_2", "control", "treatment_1"),
                 wave_4 = c("treatment_2", "control", "treatment_1")
                 )
df

mask_variables_rowwise(df, starts_with("wave_"))

```

### Masking variable names

The `mask_names()` function allows users to rename variables in a dataset to anonymous, generic labels. This is especially useful in analyses where variable names carry substantive meaning (e.g., questionnaire items, network nodes, test-items), and one wants to prevent analysts from recognizing which item is which during preprocessing or exploratory phases.

The `mask_names()` function takes a data frame and one or more variable sets, which can be specified either with tidyselect expressions (e.g., `starts_with("Q")`) or as character vectors of column names. The `prefix` argument sets the base for the masked names. For instance, in the `williams` data we can blind all variables that are related to the impulsivity scale.

```{r}
names(williams)

williams |> 
    mask_names(starts_with("Impul"), prefix = "masked_") |> 
    names()
```

Use multiple `mask_names()` calls to blind different sets of variables independently. Assigning distinct prefixes allows variables to be anonymized while preserving information about their original clusters. For example, an analyst can recognize that a set of variables belongs to the same construct—enabling procedures such as factor analysis or reliability estimation—without knowing which specific items are being evaluated. The example below demonstrates this clustered masking approach in a pipe-based workflow.

```{r}
masked_williams <- 
    williams |> 
    mask_names(starts_with("SexUnres"), prefix = "masked_set_A_") |>  
    mask_names(starts_with("Impul"), prefix = "masked_set_B_") |> 
    mask_names(starts_with("Opport"), prefix = "masked_set_C_") |> 
    mask_names(starts_with("InvEdu"), prefix = "masked_set_D_") |> 
    mask_names(starts_with("InvChild"), prefix = "masked_set_E_")

names(masked_williams)
```

Once masked, one can proceed with analyses (e.g. factor analysis, network analysis) on the masked variables, without knowing which original items correspond to which columns. For example, we can run a factor analysis on the masked items:

```{r}
masked_williams |> 
  select(starts_with("masked_set")) |> 
  factanal(factors = 3, rotation = "varimax") |> 
  loadings() |> 
  print(cutoff = 0.3, sort = TRUE)
```

Because the column names are anonymized, any decisions about factor inclusion or rotation are made blind to the substantive meaning of items, reducing the risk of interpretive bias.

In short, `mask_names()` supports naming-based blinding by decoupling analysis from semantic content, while preserving the full data structure needed for legitimate exploratory workflows.

## Scrambling functions

Scrambling functions randomize the order of values while preserving all original data content. This approach maintains the data distribution while breaking the connection between observations and their original values. The `scramble_values()` function randomly reorders the elements of a vector. The vector can contain numeric, character, or factor type data. Scrambling is useful when we want to preserve the original values but eliminate any correspondence between observations and their values.

```{r}
# Numeric data
numbers <- 1:10
scramble_values(numbers)
```

The `scramble_variables()` function extends the scrambling functionality to data frames. It allows scrambling multiple columns simultaneously, with options for independent scrambling, joint scrambling, and within-group scrambling. Columns can be selected using tidyselect helpers. For instance, in the williams data we could choose to scramble the columns age (a demographic variable) and ecology (the identifier of the experimental condition) as follows:

```{r}

williams_example <-
    williams |>
    select(subject, age, ecology) |> 
    head()

williams_example

scramble_variables(williams_example, c("age", "ecology"))

```

By default, columns are scrambled independently. Setting `together = TRUE` causes the selected columns to be scrambled jointly, preserving their row-wise associations. Adding this argument to the previous example therefore maintains the relationship between the two scrambled variables.

```{r}
scramble_variables(williams_example, c("age", "ecology"), together = TRUE)
```

Scrambling can be done in groups using the `.groups` parameter. This ensures that values are only scrambled within their original groups. In the following example, we scramble the columns x and y within each group defined by the group column:

```{r}
df <- data.frame(x = 1:6,
                 y = letters[1:6],
                 group = c("A", "A", "A", "B", "B", "B")
                 )
df 

scramble_variables(df, c("x", "y"), .groups = "group")

```

The `scramble_variables_rowwise()` function scrambles values within each row across specified columns. This is useful for scrambling repeated measures or item responses. Within each row, the values are shuffled among the item columns. You can scramble multiple sets of columns independently. The function can use tidyselect helpers. In the next example, we scramble values across three day variables for each participant in a hypothetical dataset:

```{r}
df_wide <- data.frame(
  day_1 = c(1, 4, 7),
  day_2 = c(2, 5, 8),
  day_3 = c(3, 6, 9),
  score_a = c(10, 40, 70),
  score_b = c(20, 50, 80),
  id = 1:3
)

df_wide

scramble_variables_rowwise(df_wide, starts_with("day_"), c("score_a", "score_b"))
```

# Summary 

The introduction of \pkg{vazul} fills a notable gap in the \proglang{R} ecosystem, as no dedicated package currently exists to specifically address the diverse requirements of analysis blinding. While some basic blinding tasks—such as simple vector permutations—can be achieved using base \proglang{R} or \pkg{tidyverse} functions like sample() or mutate(), these manual approaches quickly become error-prone as study designs grow in complexity. When dealing with multiple independent variables, hierarchical data structures, or the need for consistent masking across several columns, the risk of "breaking" the data structure or accidentally unblinding the analyst increases significantly. By providing a unified and tested framework, \pkg{vazul} abstracts these technical intricacies, and allow researchers to focus on the conceptual rigor of their analysis plans rather than the underlying data manipulation logic.

The functions implemented in \pkg{vazul} are applicable to a wide range of paradigms and data structures and simplify the blinding process, which in turn facilitates the assignment of data-blinding roles within research teams. Specifically, since data blinding no longer requires implementing custom code the data-manager role need not be filled by an expert in the analytic method or data domain. Instead, junior lab members or external collaborators can manage data blinding, while domain experts develop the analytic strategy.

Beyond standalone use in \proglang{R} scripts, the package's modular design makes it an ideal candidate for integration into other statistical software platforms. For instance, the inclusion of \pkg{vazul} as a back-end for the \proglang{JASP} [@JASP2025] graphical interface could provide a point-and-click solution for analysis blinding, further facilitating the adoption of these best practices across the social and behavioral sciences. 

# Acknowledgements

Tamás Nagy was supported by the University Excellence Fund of Eötvös Loránd University, Budapest, Hungary (ELTE), and the János Bolyai research fellowship of the Hungarian Academy of Sciences. Alexandra Sarafoglou was supported by an 2024 Ammodo Science Award.


# References
