---
documentclass: jss
author:
  - name: Tamás Nagy
    orcid: 00000-0001-5244-0356
    address: |
      | Institute of Psychology,
      | ELTE Eotvos Lorend University,
      | Budapest, Hungary
    affiliation: |
      | ELTE Eotvos Lorend University
    email: \email{nagy.tamas@ppk.elte.hu} \AND
  - name: Alexandra Sarafoglou
    orcid: 0000-0003-0031-685X
    address: |
      | Department of Psychology,
      | University of Amsterdam,
      | Amsterdam, The Netherlands
    affiliation: |
      | University of Amsterdam
    email: \email{a.s.g.sarafoglou@uva.nl} 
title:
  formatted: "\\pkg{Vazul}: An R Package for Analysis Blinding"
  # If you use tex in the formatted title, also supply version without
  plain:     "An R Package for Analysis Blinding"
  # For running headers, if needed
  short:     "\\pkg{Vazul}: A Capitalized Title"
abstract: >
  The abstract of the article.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
preamble: >
  \usepackage{amsmath}
output: rticles::jss_article
bibliography: ../inst/bibliography.bib
csl: jss.csl   # optional, if you want JSS citation style
---

```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')
```

# Introduction

In data analysis, researchers face the challenge of maintaining objectivity and minimizing bias. A central concern is the considerable analytic flexibility present at various stages of the workflow, including data preprocessing, variable selection, model specification, and statistical testing. This flexibility has been described as the ``garden of forking paths'' [@gelman2013garden], meaning that possibly hundreds or thousands of plausible, non-redundant analytic strategies can be applied to the same dataset [@steegen2016increasing; @SimonsohnEtAl2020]. Crucially, different analytic paths can yield different results, and analysts may, intentionally or not, gravitate toward those that align with their expectations. 

The result can be biased or even spurious findings [@ioannidis2005most; @simmons2011false; @gelman2016statistical], which have eroded trust in science and contributed to replication failures across medical sciences, psychology, economics, and computer science [@ioannidis2005contradicted; @open2015estimating; @baker2016scientists; @nosek2022replicability; @pashler2012editors; @camerer2016evaluating; @cockburn2020threats].^[But see @gilbert2016, @muradchanian2021best, @savitz2024responding, and @mcshane2024statistical for critiques of how replication failure is measured and of the design and validity of some replication attempts.] To ensure the reliability of empirical findings, it is therefore essential to prevent the idiosyncrasies of the data from feeding back into the formulation of the hypotheses being tested [HARKing, @kerr1998harking] or from prompting researchers to exploit their analytic freedom to accentuate desired outcomes [@simmons2011false]. In response, researchers have proposed methodologies to limit the influence of bias in data analysis. One such method is analysis blinding, which supplies analysts with an altered version of the real data that conceals biasing features until the analysis plan is finalized.

Analysis blinding, or blind analysis [@maccoun2015hide], is a methodological approach designed to protect the confirmatory status of an analysis by concealing crucial test-relevant aspects of the data from the analysts—for example, by scrambling dependent variables or masking key labels. The procedure typically involves two independent parties: a data manager, who has full access to the raw data and is responsible for implementing the blinding steps, and an analyst, who is tasked with developing the analysis plan. After the data manager applies the blinding procedure, the analyst receives the resulting modified dataset: the blinded data.

Working with the blinded data, the analyst can explore and preprocess the dataset and develop an analysis plan without being influenced by whether a particular analytic choice produces the desired result, as any patterns in the blinded data are, by design, only a product of chance. Importantly, although the test-relevant elements are concealed, other meaningful characteristics remain intact, including demographic information, secondary variables, and the distributional properties of both dependent and independent variables. As a result, the analyst retains all information necessary to tailor the analytic approach to the specific, and potentially unexpected, features of the data. Once the analysis plan has been finalized using the blinded data, the analyst is granted access to the raw, unblinded dataset, and the confirmatory analysis can then be carried out strictly according to the pre-established plan.

Analysis blinding ties in with other methodologies to minimize bias in the research cycle, such as single-blind or double-blind experimental designs, where participants and/or experimenters are unaware of certain aspects of the study to prevent bias in data collection [@schulz2002blinding]. Here, the analysts is intentionally kept unaware of certain aspects of the data to prevent bias in data analysis, which is why the methodology is also referred to as triple-blind [@schulz2002blinding]. 

Although many blinding techniques are conceptually straightforward, such as scrambling outcome variables or masking variable names and factor labels, their practical implementation can become technically challenging once real research designs and data structures are considered. For instance, in hierarchical models, researchers may need to scramble the outcome variable to destroy the effect of interest while still preserving information within grouping levels, such as country-level means in cross-cultural datasets [e.g., @sarafoglou2023comparing]. Similarly, in repeated-measures designs, condition labels may need to be masked so that each participant’s condition structure is preserved while permuting the mapping of conditions across participants to obscure the true experimental effect. These complexities make manual analysis blinding difficult to carry out consistently and correctly. To lower barriers for data managers and facilitate the broader adoption of analysis blinding in research labs, dedicated software tools, such as \proglang{R} packages, are needed to implement these procedures reliably.

To meet this need, the \pkg{vazul} package in \proglang{R} \url{(https://CRAN.R-project.org/package=vazul)} offers flexible and reproducible tools for implementing analysis blinding. It provides functionality for data scrambling as well as data and variable masking. In the remainder of this article, we introduce the methodology in more detail, describe the functionalities of the \pkg{vazul} package, and illustrate its application through practical examples. We conclude with a brief discussion and outline future directions.

## Analysis Blinding: Safeguarding Against Bias Without Preregistration

Originally, analysis blinding gained traction in astrophysics in the early 2000s [@maccoun2018psychological] as a means of safeguarding analysts against bias. Since then, the methodology has also been advocated in the social and behavioral sciences as an alternative or complement to preregistration [@dutilh2021blinding; @nagy2025bestiary; @maccoun2021removebiases; @maccoun2015hide; @maccoun2018psychological; @aczel2020transparency]. 
<!-- However, the field has largely developed in a different direction: here, the predominant approach for limiting analytic flexibility is the preregistration of analysis plans, that is, requiring researchers to specify their planned analyses before data collection begins or before they view the data (e.g., existing estimates of preregistration rates in empirical psychology published in prominent journals range from about 14% @hardwicke2024prevalence2024 to about 40% @pfadt2025practicesPreprint). In the literature, analysis blinding has been proposed as an alternative or complementary method to preregistration [e.g., @dutilh2021blinding] as it addresses several of preregistration's major shortcomings.  -->
This interest partly reflects the fact that analysis blinding addresses several of preregistration's major shortcomings. Preregistration can restrict analysts so rigidly that they are unable to adapt their analyses to unexpected peculiarities in the data. Although deviations from preregistered plans are both possible and accepted when transparently disclosed in the final manuscript, such deviations run counter to the spirit of preregistration, as they reintroduce data-dependent decisions that may bias the results. At the same time, text-based preregistrations, that is, the description of analysis plans in a preregistration template, often fail to be ``specific, precise, and exhaustive'' [@wicherts2016degrees, p.2], which leaves substantial degrees of freedom unaccounted for.

In contrast to preregistration, analysis blinding allows researchers to maintain flexibility in their analysis plans, as they can explore the data without being constrained by a rigid preregistered protocol. This flexibility is especially important in analyses involving advanced statistical modeling or preprocessing, where not all decisions can be anticipated in advance and researchers must make data-dependent choices. For instance, many psychological constructs, such as well-being, are measured with multi-item scales whose factor structure must be examined before further analysis; whether the items load onto a single factor or multiple factors determines subsequent analytic steps, including whether composite scores can be computed or whether a more complex measurement model is required [see e.g., @MARP2022discussion]. The flexibility gained by analysis blinding enables researchers to develop analysis strategies that are appropriately tailored to the specific characteristics of the dataset without the need to anticipate and specify all eventualities in advance. Consequently, researchers who analyze their data with analysis blinding are less likely to deviate from their developed analysis plan compared to researchers who preregister their analytic strategy in a text-based format [@sarafoglou2023comparing].

Moreover, similar in spirit to approaches proposed in code-based preregistration [@peikert2021reproducible;@vanlissa2021worcs], analysis blinding naturally produces analysis plans that are specific, precise, and exhaustive, because they are written directly in code rather than described verbally in preregistration templates. As with preregistration, analysis scripts based on the blinded data can be uploaded or attached to preregistration platforms (e.g., the Open Science Framework) to provide a transparent record of the planned analysis before the data are unblinded. In short, analysis blinding can serve as a valuable alternative or additional safeguard to preregistered analysis plans: it effectively protects against bias while providing analysts with the flexibility needed to develop an analysis strategy that is optimally suited to their data.

# References
